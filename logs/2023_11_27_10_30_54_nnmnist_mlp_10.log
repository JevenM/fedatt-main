2023-11-27 10:30:55,070 - INFO - MLP(
  (layer_input): Linear(in_features=784, out_features=64, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0.5, inplace=False)
  (layer_hidden): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
2023-11-27 10:31:08,861 - INFO - Train loss: -0.4408513091997043
2023-11-27 10:31:20,908 - INFO - Train loss: -0.7287046898529728
2023-11-27 10:31:33,418 - INFO - Train loss: -0.797810102894362
2023-11-27 10:31:45,966 - INFO - Train loss: -0.8264672449275628
2023-11-27 10:31:58,582 - INFO - Train loss: -0.8412764193788012
2023-11-27 10:32:11,038 - INFO - Train loss: -0.8517095444044833
2023-11-27 10:32:23,513 - INFO - Train loss: -0.8595587022777306
2023-11-27 10:32:36,265 - INFO - Train loss: -0.8651261721719811
2023-11-27 10:32:49,020 - INFO - Train loss: -0.8704194633691296
2023-11-27 10:33:01,876 - INFO - Train loss: -0.8748749938092506
2023-11-27 10:33:04,021 - INFO - Results after 10 rounds of training:
2023-11-27 10:33:04,022 - INFO - |---- Test on 10000 samples
2023-11-27 10:33:04,022 - INFO - |---- Test Accuracy: 92.64%
2023-11-27 10:33:04,022 - INFO - Total Run Time 00:02:09
2023-11-27 10:33:04,212 - INFO - [-0.4408513091997043, -0.7287046898529728, -0.797810102894362, -0.8264672449275628, -0.8412764193788012, -0.8517095444044833, -0.8595587022777306, -0.8651261721719811, -0.8704194633691296, -0.8748749938092506]
